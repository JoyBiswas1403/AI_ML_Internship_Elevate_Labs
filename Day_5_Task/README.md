# ğŸŒ³ Task 5: Decision Trees & Random Forests â€“ AI & ML Internship

**Name:** Joy Biswas  

---

## ğŸ“‹ Overview

This task applies **Decision Tree** and **Random Forest** classifiers to predict heart disease presence using the **Heart Failure Clinical Records Dataset**.  

It demonstrates:
- Training & evaluating decision trees and ensemble models
- Controlling overfitting via limited tree depth
- Feature importance analysis
- Visualizing model decisions & metrics
- Comparing performance with cross-validation

---

## ğŸ“‚ Dataset

**Source:** [Heart Failure Clinical Records Dataset (GitHub)](https://raw.githubusercontent.com/anik199/Heart-failure-prediction/main/heart.csv)  
**Records:** 918  
**Features:** 12 patient health indicators  
**Target Variable:** `HeartDisease`  
(1 = Disease, 0 = No Disease)

**Preprocessing:**
- Encoded categorical variables (`Sex`, `ExerciseAngina`, `ChestPainType`, `RestingECG`, `ST_Slope`)
- One-hot encoding for multi-category features

---

## âœ… Steps Performed

1. ğŸ“¥ Load & explore dataset  
2. ğŸ§¹ Encode categorical features  
3. ğŸŒ³ Train full-depth Decision Tree  
4. âœ‚ï¸ Limit tree depth (`max_depth=3`) to reduce overfitting  
5. ğŸŒ² Train Random Forest (`n_estimators=100`, `max_depth=5`)  
6. ğŸ“Š Evaluate using accuracy & 5â€‘fold CV  
7. ğŸ” Interpret:
   - Tree diagram (`screenshots/decision_tree.png`)
   - Feature importance (`screenshots/feature_importance.png`)
8. ğŸ’¾ Save cleaned dataset & visualizations

---

## ğŸ“ˆ Results Summary

| Model                             | Test Accuracy | CV Accuracy |
|-----------------------------------|--------------:|------------:|
| Decision Tree (full depth)        | **88.50%**    | **87.30%**  |
| Decision Tree (`max_depth=3`)     | **86.90%**    | **87.30%**  |
| Random Forest (`max_depth=5`)     | **90.20%**    | **89.40%**  |

**Top Features by Random Forest:**  
Shown in `screenshots/feature_importance.png`

---

## ğŸ“ Files in this Folder

- `task5_decision_trees_random_forest.ipynb` / `.py` â€“ Complete code  
- `cleaned_heart_failure.csv` â€“ Final cleaned dataset  
- `screenshots/decision_tree.png` â€“ Visualization of Decision Tree (`max_depth=3`)  
- `screenshots/feature_importance.png` â€“ Feature importance chart  
- `screenshots/confusion_matrix.png` â€“ Confusion Matrix for Random Forest predictions  
- `README.md` â€“ This documentation

---

## â–¶ï¸ How to Run

1. Clone this repo or open in Colab/Jupyter.  
2. Install requirements:  
3. Run all cells in the `.ipynb` or `.py` file.  
4. View metrics in console and images in `screenshots/`.  
5. (In Colab) Uncomment `files.download()` lines to save outputs locally.

---

## ğŸ“¬ Contact

ğŸ“§ **bjoy1403@gmail.com**  
ğŸ™ Open a GitHub issue in this repo

---

**Author:** Joy Biswas  
**Program:** Elevate AI & ML Internship  

---

â­ If you find this project useful, please star â­ the repo!
